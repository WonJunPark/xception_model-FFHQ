{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colaboratory에 오신 것을 환영합니다",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WonJunPark/xception_model-FFHQ/blob/master/Colaboratory%EC%97%90_%EC%98%A4%EC%8B%A0_%EA%B2%83%EC%9D%84_%ED%99%98%EC%98%81%ED%95%A9%EB%8B%88%EB%8B%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZjqlcisUi76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_colab = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe8F5tMFUi-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "4682a68b-cd4e-4d00-df8e-9da4bb6cc497"
      },
      "source": [
        "if use_colab == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw0NSK7aUjAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_colab == True:\n",
        "  work_root_path = \"/content/gdrive/My Drive/Kaggle/DFDC2/\"\n",
        "else:\n",
        "  work_root_path = \"../\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkDiFY5pUjC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "935e5824-9f96-49f5-9a12-b31f87e689aa"
      },
      "source": [
        "cd \"/content/gdrive/My Drive\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63ixGm74UmP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm,trange\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAkc3QgPVDwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train0 = pd.read_json(work_root_path+'input/deepfake/metadata0.json')\n",
        "df_train1 = pd.read_json(work_root_path+'input/deepfake/metadata1.json')\n",
        "df_train2 = pd.read_json(work_root_path+'input/deepfake/metadata2.json')\n",
        "df_train3 = pd.read_json(work_root_path+'input/deepfake/metadata3.json')\n",
        "df_train4 = pd.read_json(work_root_path+'input/deepfake/metadata4.json')\n",
        "df_train5 = pd.read_json(work_root_path+'input/deepfake/metadata5.json')\n",
        "df_train6 = pd.read_json(work_root_path+'input/deepfake/metadata6.json')\n",
        "df_train7 = pd.read_json(work_root_path+'input/deepfake/metadata7.json')\n",
        "df_train8 = pd.read_json(work_root_path+'input/deepfake/metadata8.json')\n",
        "df_train9 = pd.read_json(work_root_path+'input/deepfake/metadata9.json')\n",
        "df_train10 = pd.read_json(work_root_path+'input/deepfake/metadata10.json')\n",
        "df_train11 = pd.read_json(work_root_path+'input/deepfake/metadata11.json')\n",
        "df_train12 = pd.read_json(work_root_path+'input/deepfake/metadata12.json')\n",
        "df_train13 = pd.read_json(work_root_path+'input/deepfake/metadata13.json')\n",
        "df_train14 = pd.read_json(work_root_path+'input/deepfake/metadata14.json')\n",
        "df_train15 = pd.read_json(work_root_path+'input/deepfake/metadata15.json')\n",
        "df_train16 = pd.read_json(work_root_path+'input/deepfake/metadata16.json')\n",
        "df_train17 = pd.read_json(work_root_path+'input/deepfake/metadata17.json')\n",
        "df_train18 = pd.read_json(work_root_path+'input/deepfake/metadata18.json')\n",
        "df_train19 = pd.read_json(work_root_path+'input/deepfake/metadata19.json')\n",
        "df_train20 = pd.read_json(work_root_path+'input/deepfake/metadata20.json')\n",
        "df_train21 = pd.read_json(work_root_path+'input/deepfake/metadata21.json')\n",
        "df_train22 = pd.read_json(work_root_path+'input/deepfake/metadata22.json')\n",
        "df_train23 = pd.read_json(work_root_path+'input/deepfake/metadata23.json')\n",
        "df_train24 = pd.read_json(work_root_path+'input/deepfake/metadata24.json')\n",
        "df_train25 = pd.read_json(work_root_path+'input/deepfake/metadata25.json')\n",
        "df_train26 = pd.read_json(work_root_path+'input/deepfake/metadata26.json')\n",
        "df_train27 = pd.read_json(work_root_path+'input/deepfake/metadata27.json')\n",
        "df_train28 = pd.read_json(work_root_path+'input/deepfake/metadata28.json')\n",
        "df_train29 = pd.read_json(work_root_path+'input/deepfake/metadata29.json')\n",
        "df_train30 = pd.read_json(work_root_path+'input/deepfake/metadata30.json')\n",
        "df_train31 = pd.read_json(work_root_path+'input/deepfake/metadata31.json')\n",
        "df_train32 = pd.read_json(work_root_path+'input/deepfake/metadata32.json')\n",
        "df_train33 = pd.read_json(work_root_path+'input/deepfake/metadata33.json')\n",
        "df_train34 = pd.read_json(work_root_path+'input/deepfake/metadata34.json')\n",
        "df_train35 = pd.read_json(work_root_path+'input/deepfake/metadata35.json')\n",
        "df_train36 = pd.read_json(work_root_path+'input/deepfake/metadata36.json')\n",
        "df_train37 = pd.read_json(work_root_path+'input/deepfake/metadata37.json')\n",
        "df_train38 = pd.read_json(work_root_path+'input/deepfake/metadata38.json')\n",
        "df_train39 = pd.read_json(work_root_path+'input/deepfake/metadata39.json')\n",
        "df_train40 = pd.read_json(work_root_path+'input/deepfake/metadata40.json')\n",
        "df_train41 = pd.read_json(work_root_path+'input/deepfake/metadata41.json')\n",
        "df_train42 = pd.read_json(work_root_path+'input/deepfake/metadata42.json')\n",
        "df_train43 = pd.read_json(work_root_path+'input/deepfake/metadata43.json')\n",
        "df_train44 = pd.read_json(work_root_path+'input/deepfake/metadata44.json')\n",
        "df_train45 = pd.read_json(work_root_path+'input/deepfake/metadata45.json')\n",
        "df_train46 = pd.read_json(work_root_path+'input/deepfake/metadata46.json')\n",
        "df_val1 = pd.read_json(work_root_path+'input/deepfake/metadata47.json')\n",
        "df_val2 = pd.read_json(work_root_path+'input/deepfake/metadata48.json')\n",
        "df_val3 = pd.read_json(work_root_path+'input/deepfake/metadata49.json')\n",
        "df_trains = [df_train0 ,df_train1, df_train2, df_train3, df_train4,\n",
        "             df_train5, df_train6, df_train7, df_train8, df_train9,df_train10,\n",
        "            df_train11, df_train12, df_train13, df_train14, df_train15,df_train16, \n",
        "            df_train17, df_train18, df_train19, df_train20, df_train21, df_train22, \n",
        "            df_train23, df_train24, df_train25, df_train26, df_train27, df_train28, \n",
        "            df_train29, df_train30, df_train31, df_train32, df_train33, df_train34,\n",
        "            df_train34, df_train35, df_train36, df_train37, df_train38, df_train39,\n",
        "            df_train40, df_train41, df_train42, df_train43, df_train44, df_train45,\n",
        "            df_train46]\n",
        "df_vals=[df_val1, df_val2, df_val3]\n",
        "nums = list(range(len(df_trains)+1))\n",
        "LABELS = ['REAL','FAKE']\n",
        "val_nums=[47, 48, 49]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5YKsyl2VENj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fa60c527-d032-4e9f-a621-853412264e08"
      },
      "source": [
        "def get_path(num,x):\n",
        "    num=str(num)\n",
        "    if len(num)==2:\n",
        "        path= work_root_path + 'input/deepfake/DeepFake'+num+'/DeepFake'+num+'/' + x.replace('.mp4', '') + '.jpg'\n",
        "    else:\n",
        "        path= work_root_path + 'input/deepfake/DeepFake0'+num+'/DeepFake0'+num+'/' + x.replace('.mp4', '') + '.jpg'\n",
        "    if not os.path.exists(path):\n",
        "       raise Exception\n",
        "    return path\n",
        "paths=[]\n",
        "y=[]\n",
        "for df_train,num in tqdm(zip(df_trains,nums),total=len(df_trains)):\n",
        "    images = list(df_train.columns.values)\n",
        "    for x in images:\n",
        "        try:\n",
        "            paths.append(get_path(num,x))\n",
        "            y.append(LABELS.index(df_train[x]['label']))\n",
        "        except Exception as err:\n",
        "            #print(err)\n",
        "            pass\n",
        "\n",
        "val_paths=[]\n",
        "val_y=[]\n",
        "for df_val,num in tqdm(zip(df_vals,val_nums),total=len(df_vals)):\n",
        "    images = list(df_val.columns.values)\n",
        "    for x in images:\n",
        "        try:\n",
        "            val_paths.append(get_path(num,x))\n",
        "            val_y.append(LABELS.index(df_val[x]['label']))\n",
        "        except Exception as err:\n",
        "            #print(err)\n",
        "            pass"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 48/48 [17:53<00:00, 42.26s/it]\n",
            "100%|██████████| 3/3 [00:48<00:00, 12.94s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iLRsPalVEQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_img(path):\n",
        "    return cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)\n",
        "\n",
        "def shuffle(X,y):\n",
        "    new_train=[]\n",
        "    for m,n in zip(X,y):\n",
        "        new_train.append([m,n])\n",
        "    random.shuffle(new_train)\n",
        "    X,y=[],[]\n",
        "    for x in new_train:\n",
        "        X.append(x[0])\n",
        "        y.append(x[1])\n",
        "    return X,y\n",
        "\n",
        "import random\n",
        "def get_random_sampling(paths, y, val_paths, val_y):\n",
        "  real=[]\n",
        "  fake=[]\n",
        "  for m,n in zip(paths,y):\n",
        "      if n==0:\n",
        "          real.append(m)\n",
        "      else:\n",
        "          fake.append(m)\n",
        "  # fake=random.sample(fake,len(real))\n",
        "  paths,y=[],[]\n",
        "  for x in real:\n",
        "      paths.append(x)\n",
        "      y.append(0)\n",
        "  for x in fake:\n",
        "      paths.append(x)\n",
        "      y.append(1)\n",
        "\n",
        "  real=[]\n",
        "  fake=[]\n",
        "  for m,n in zip(val_paths,val_y):\n",
        "      if n==0:\n",
        "          real.append(m)\n",
        "      else:\n",
        "          fake.append(m)\n",
        "  # fake=random.sample(fake,len(real))\n",
        "  val_paths,val_y=[],[]\n",
        "  for x in real:\n",
        "      val_paths.append(x)\n",
        "      val_y.append(0)\n",
        "  for x in fake:\n",
        "      val_paths.append(x)\n",
        "      val_y.append(1)\n",
        "\n",
        "  X=[]\n",
        "  for img in tqdm(paths):\n",
        "      X.append(read_img(img))\n",
        "  val_X=[]\n",
        "  for img in tqdm(val_paths):\n",
        "      val_X.append(read_img(img))\n",
        "\n",
        "  # Balance with ffhq dataset\n",
        "  ffhq = os.listdir('/content/gdrive/My Drive/Kaggle/DFDC2/input/ffhq-face-data-set/thumbnails128x128')\n",
        "  X_ = []\n",
        "  for file in tqdm(ffhq):\n",
        "    im = read_img(f'/content/gdrive/My Drive/Kaggle/DFDC2/input/ffhq-face-data-set/thumbnails128x128/{file}')\n",
        "    im = cv2.resize(im, (150,150))\n",
        "    X_.append(im)\n",
        "  random.shuffle(X_)\n",
        "\n",
        "  for i in range(64773 - 12130):\n",
        "    X.append(X_[i])\n",
        "    y.append(0)\n",
        "  del X_[0:64773 - 12130]\n",
        "  for i in range(6108 - 1258):\n",
        "    val_X.append(X_[i])\n",
        "    val_y.append(0)\n",
        "\n",
        "  X, y = shuffle(X,y)\n",
        "  val_X, val_y = shuffle(val_X,val_y)\n",
        "\n",
        "  return X, val_X, y, val_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b49f78FVESg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, X, y, training=True, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "        self.training = training\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        img = self.X[idx]\n",
        "\n",
        "        if self.transform is not None:\n",
        "          res = self.transform(image=img)\n",
        "          img = res['image']\n",
        "        \n",
        "        img = np.rollaxis(img, 2, 0)\n",
        "        # img = np.array(img).astype(np.float32) / 255.\n",
        "\n",
        "        labels = self.y[idx]\n",
        "        labels = np.array(labels).astype(np.float32)\n",
        "        return [img, labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF-iSy6BWjR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "27ee5717-5e0d-479f-aaba-95ffa77f147d"
      },
      "source": [
        "!pip install pytorchcv --quiet\n",
        "from pytorchcv.model_provider import get_model\n",
        "model = get_model(\"xception\", pretrained=True)\n",
        "# model = get_model(\"resnet18\", pretrained=True)\n",
        "model = nn.Sequential(*list(model.children())[:-1]) # Remove original output layer"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▉                               | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 92kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 102kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 122kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 133kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 143kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 153kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 163kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 174kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 184kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 194kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 204kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 215kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 225kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 235kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 245kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 256kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 266kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 276kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 286kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 296kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 307kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 317kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 327kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 337kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 348kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 358kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 368kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 378kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 389kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 399kB 3.0MB/s \n",
            "\u001b[?25hDownloading /root/.torch/models/xception-0549-e4f0232c.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.115/xception-0549-e4f0232c.pth.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z716H8crWjUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model[0].final_block.pool = nn.Sequential(nn.AdaptiveAvgPool2d(1))\n",
        "# model[0].final_pool = nn.Sequential(nn.AdaptiveAvgPool2d(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D_711MLWjWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Head(torch.nn.Module):\n",
        "  def __init__(self, in_f, out_f):\n",
        "    super(Head, self).__init__()\n",
        "    \n",
        "    self.f = nn.Flatten()\n",
        "    self.l = nn.Linear(in_f, 512)\n",
        "    self.d = nn.Dropout(0.75)\n",
        "    self.o = nn.Linear(512, out_f)\n",
        "    self.b1 = nn.BatchNorm1d(in_f)\n",
        "    self.b2 = nn.BatchNorm1d(512)\n",
        "    self.r = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.f(x)\n",
        "    x = self.b1(x)\n",
        "    x = self.d(x)\n",
        "\n",
        "    x = self.l(x)\n",
        "    x = self.r(x)\n",
        "    x = self.b2(x)\n",
        "    x = self.d(x)\n",
        "\n",
        "    out = self.o(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inM2Cj_nWjYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FCN(torch.nn.Module):\n",
        "  def __init__(self, base, in_f):\n",
        "    super(FCN, self).__init__()\n",
        "    self.base = base\n",
        "    self.h1 = Head(in_f, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.base(x)\n",
        "    return self.h1(x)\n",
        "\n",
        "model = FCN(model, 2048)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTJFfwE6WjbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install torchtoolbox --quiet\n",
        "# from torchtoolbox.tools import summary\n",
        "\n",
        "# model.cuda()\n",
        "# summary(model, torch.rand((1, 3, 150, 150)).cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0HfK6sdWrqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def criterion1(pred1, targets):\n",
        "  l1 = F.binary_cross_entropy(F.sigmoid(pred1), targets)\n",
        "  return l1\n",
        "\n",
        "def train_model(epoch, optimizer, scheduler=None, history=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    t = tqdm(train_loader)\n",
        "    for i, (img_batch, y_batch) in enumerate(t):\n",
        "        img_batch = img_batch.cuda().float()\n",
        "        y_batch = y_batch.cuda().float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(img_batch)\n",
        "        loss = criterion1(out, y_batch)\n",
        "\n",
        "        total_loss += loss\n",
        "        t.set_description(f'Epoch {epoch+1}/{n_epochs}, LR: %6f, Loss: %.4f'%(optimizer.state_dict()['param_groups'][0]['lr'],total_loss/(i+1)))\n",
        "\n",
        "        if history is not None:\n",
        "          history.loc[epoch + i / len(X), 'train_loss'] = loss.data.cpu().numpy()\n",
        "          history.loc[epoch + i / len(X), 'lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "          scheduler.step()\n",
        "\n",
        "def evaluate_model(epoch, scheduler=None, history=None):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    pred = []\n",
        "    real = []\n",
        "    with torch.no_grad():\n",
        "        for img_batch, y_batch in val_loader:\n",
        "            img_batch = img_batch.cuda().float()\n",
        "            y_batch = y_batch.cuda().float()\n",
        "\n",
        "            o1 = model(img_batch)\n",
        "            l1 = criterion1(o1, y_batch)\n",
        "            loss += l1\n",
        "            \n",
        "            for j in o1:\n",
        "              pred.append(F.sigmoid(j))\n",
        "            for i in y_batch:\n",
        "              real.append(i.data.cpu())\n",
        "    \n",
        "    pred = [p.data.cpu().numpy() for p in pred]\n",
        "    pred2 = pred\n",
        "    pred = [np.round(p) for p in pred]\n",
        "    pred = np.array(pred)\n",
        "    acc = sklearn.metrics.recall_score(real, pred, average='macro')\n",
        "\n",
        "    real = [r.item() for r in real]\n",
        "    pred2 = np.array(pred2).clip(0.1, 0.9)\n",
        "    kaggle = sklearn.metrics.log_loss(real, pred2)\n",
        "\n",
        "    loss /= len(val_loader)\n",
        "    \n",
        "    if history is not None:\n",
        "        history.loc[epoch, 'dev_loss'] = loss.cpu().numpy()\n",
        "    \n",
        "    if scheduler is not None:\n",
        "      scheduler.step(loss)\n",
        "\n",
        "    print(f'Dev loss: %.4f, Acc: %.6f, Kaggle: %.6f'%(loss,acc,kaggle))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMHWuf7F748W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b606b55-c9a6-4579-cafd-a38ba26a7648"
      },
      "source": [
        "cd '/content/gdrive/My Drive/Kaggle/DFDC2/input/deepfake/DeepFake00/DeepFake00/'"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle/DFDC2/input/deepfake/DeepFake00/DeepFake00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-BLZlTO7wnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "f6c67065-a831-40b0-db60-0b1908da101e"
      },
      "source": [
        "paths[:4]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/Kaggle/DFDC2/input/deepfake/DeepFake00/DeepFake00/vpmyeepbep.jpg',\n",
              " '/content/gdrive/My Drive/Kaggle/DFDC2/input/deepfake/DeepFake00/DeepFake00/fzvpbrzssi.jpg',\n",
              " '/content/gdrive/My Drive/Kaggle/DFDC2/input/deepfake/DeepFake00/DeepFake00/htorvhbcae.jpg',\n",
              " '/content/gdrive/My Drive/Kaggle/DFDC2/input/deepfake/DeepFake00/DeepFake00/fckxaqjbxk.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsSpcjHHWrtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "cb468ea9-7d89-4876-94ab-d18d55d1d872"
      },
      "source": [
        "X, val_X, y, val_y = get_random_sampling(paths, y, val_paths, val_y)\n",
        "\n",
        "print('There are '+str(y.count(1))+' fake train samples')\n",
        "print('There are '+str(y.count(0))+' real train samples')\n",
        "print('There are '+str(val_y.count(1))+' fake val samples')\n",
        "print('There are '+str(val_y.count(0))+' real val samples')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 76903/76903 [5:50:21<00:00,  4.06it/s]\n",
            "100%|██████████| 7366/7366 [20:04<00:00,  6.69it/s]\n",
            "  0%|          | 0/67 [00:00<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-824bcb245848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' fake train samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' real train samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' fake val samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-c5a25c244ba3>\u001b[0m in \u001b[0;36mget_random_sampling\u001b[0;34m(paths, y, val_paths, val_y)\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffhq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/gdrive/My Drive/Kaggle/DFDC2/input/ffhq-face-data-set/thumbnails128x128/{file}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mX_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-c5a25c244ba3>\u001b[0m in \u001b[0;36mread_img\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnew_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRXY5-iMWrvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "9b425db4-e625-4099-a611-83c6329b078f"
      },
      "source": [
        "import albumentations\n",
        "from albumentations.augmentations.transforms import ShiftScaleRotate, HorizontalFlip, Normalize, RandomBrightnessContrast, MotionBlur, Blur, GaussNoise, JpegCompression\n",
        "train_transform = albumentations.Compose([\n",
        "                                          ShiftScaleRotate(p=0.3, scale_limit=0.25, border_mode=1, rotate_limit=25),\n",
        "                                          HorizontalFlip(p=0.2),\n",
        "                                          RandomBrightnessContrast(p=0.3, brightness_limit=0.25, contrast_limit=0.5),\n",
        "                                          MotionBlur(p=.2),\n",
        "                                          GaussNoise(p=.2),\n",
        "                                          JpegCompression(p=.2, quality_lower=50),\n",
        "                                          Normalize()\n",
        "])\n",
        "val_transform = albumentations.Compose([\n",
        "                                          Normalize()\n",
        "])\n",
        "\n",
        "train_dataset = ImageDataset(X, y, transform=train_transform)\n",
        "val_dataset = ImageDataset(val_X, val_y, transform=val_transform)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7b72f76e1e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfCa5aRXWrxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nrow, ncol = 5, 6\n",
        "fig, axes = plt.subplots(nrow, ncol, figsize=(20, 8))\n",
        "axes = axes.flatten()\n",
        "for i, ax in enumerate(axes):\n",
        "    image, label = train_dataset[i]\n",
        "    image = np.rollaxis(image, 0, 3)\n",
        "    image = image*std + mean\n",
        "    image = np.clip(image, 0., 1.)\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(f'label: {label}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VODj1R0aWr0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "\n",
        "history = pd.DataFrame()\n",
        "history2 = pd.DataFrame()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "best = 1e10\n",
        "n_epochs = 20\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, mode='min', factor=0.7, verbose=True, min_lr=1e-5)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    train_model(epoch, optimizer, scheduler=None, history=history)\n",
        "    \n",
        "    loss = evaluate_model(epoch, scheduler=scheduler, history=history2)\n",
        "    \n",
        "    if loss < best:\n",
        "      best = loss\n",
        "      print(f'Saving best model...')\n",
        "      torch.save(model.state_dict(), f'model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktnenf4LWr2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history2.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKYucbvUiKzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}